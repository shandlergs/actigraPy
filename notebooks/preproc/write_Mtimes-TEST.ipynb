{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in .AWD, sleep log if it exists, calendar, and spits out some pretty pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/MoodGroup/actigraphy/gavi/actigraPy/actigraPy/actigraPy.py:23: MatplotlibDeprecationWarning: \n",
      "The matplotlib.backends.tkagg module was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  import matplotlib.backends.tkagg as tkagg\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, '/data/MoodGroup/actigraphy/gavi/actigraPy') \n",
    "\n",
    "import actigraPy.actigraPy as act\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run the test data, run this cell instead of the one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and log directories\n",
    "sub = 'TEST' #subject NUMBER as STRING\n",
    "sub_long = 'TEST'\n",
    "\n",
    "out_dir = '/data/MoodGroup/actigraphy/gavi/actigraPy/data/output' #output directory\n",
    "data_dir = '/data/MoodGroup/actigraphy/gavi/actigraPy/data'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject and directory info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST has cal file at /data/MoodGroup/actigraphy/gavi/actigraPy/data/TEST_calendar_log.xls\n",
      "TEST has log file at /data/MoodGroup/actigraphy/gavi/actigraPy/data/TEST_sleeplog.xls\n"
     ]
    }
   ],
   "source": [
    "fn = {}\n",
    "#.AWD\n",
    "awd_fn = os.path.join(data_dir, '%s.AWD'%sub_long)\n",
    "#sleeplog\n",
    "fn['cal']= os.path.join(data_dir, '%s_calendar_log.xls'%sub_long)\n",
    "#calendar\n",
    "fn['log'] = os.path.join(data_dir, '%s_sleeplog.xls'%sub_long)\n",
    "logs = []\n",
    "\n",
    "if os.path.isfile(awd_fn):\n",
    "    for name in fn.keys():\n",
    "        if os.path.isfile(fn[name]):\n",
    "            print(\"%s has %s file at %s\"%(sub,name,fn[name]))\n",
    "            logs.append(fn[name])\n",
    "        else:\n",
    "            print(\"no \" + name)\n",
    "            fn[name] = ''\n",
    "else:\n",
    "    print(\"DO NOT CONTINUE!! THERE IS NO AWD FILE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Mtimes file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out where to clip awd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/MoodGroup/actigraphy/gavi/actigraPy/data/TEST_calendar_log.xls\n",
      "     OffDate   OffTime     OnDate    OnTime                Comment\n",
      "0        NaT       NaN 2016-02-08  10:00:00                  start\n",
      "1 2016-02-07  13:00:00 2016-02-07  14:30:00  Fake, for bug testing\n",
      "2 2016-02-08  13:00:00 2016-02-08  14:30:00                     3T\n",
      "3 2016-02-08  21:30:00 2016-02-09  07:00:00            Sleep study\n",
      "4 2016-02-09  14:00:00 2016-02-09  16:00:00                     7T\n",
      "5 2016-02-10  10:00:00 2016-02-10  12:00:00                    MEG\n",
      "6 2016-02-10  21:30:00 2016-02-11  07:00:00            Sleep study\n",
      "7 2016-02-11  09:00:00 2016-02-11  09:40:00               Infusion\n",
      "8 2016-02-11  15:00:00 2016-02-11  17:00:00                    MEG\n",
      "warning: missing index 07-Feb-16 01:00 PM\n",
      "warning: missing index 07-Feb-16 02:30 PM\n",
      "warning: missing index 08-Feb-16 01:00 PM\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pos' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-47617af4fb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlog_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mawd_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'watch_on'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/MoodGroup/actigraphy/gavi/actigraPy/actigraPy/actigraPy.py\u001b[0m in \u001b[0;36mread_log\u001b[0;34m(fn, awd_dat)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mlog_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmk_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mlog_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mlog_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'pos' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#read AWD file\n",
    "awd_dat = act.read_AWD(awd_fn)\n",
    "idx={'start':[0],'end':[len(awd_dat['dt_list'])-1]}\n",
    "#get the start and stops from each log if they exist\n",
    "for log in logs:\n",
    "    print(log)\n",
    "    log_dat, kw_dat, comments = act.read_log(log,awd_dat)\n",
    "    \n",
    "    if 'watch_on' in kw_dat.keys():\n",
    "        on_date = kw_dat['watch_on'].iloc[0]['OnDate']\n",
    "        on_time = kw_dat['watch_on'].iloc[0]['OnTime']\n",
    "        on = datetime(on_date.year,on_date.month,on_date.day,on_time.hour,on_time.minute)\n",
    "        #check if that time is in dt_list:\n",
    "        if awd_dat['dt_list'].count(on) > 0:\n",
    "            on_idx=awd_dat['dt_list'].index(on)\n",
    "            idx['start'].append(on_idx)\n",
    "\n",
    "    if 'watch_off' in kw_dat.keys():\n",
    "        off_date = kw_dat['watch_off'].iloc[0]['OffDate']\n",
    "        off_time = kw_dat['watch_off'].iloc[0]['OffTime']\n",
    "        off = datetime(off_date.year,off_date.month,off_date.day,off_time.hour,off_time.minute)\n",
    "        if awd_dat['dt_list'].count(off) > 0:\n",
    "            off_idx=awd_dat['dt_list'].index(off)\n",
    "            idx['end'].append(off_idx)\n",
    " \n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = max(idx['start'])\n",
    "end = min(idx['end'])\n",
    "print('start = %d, end = %d'%(start,end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Make sure the starts and ends make sense before clipping the data</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5dd2e5946ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#modify these according to output from above!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mawd_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mawd_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclip_dat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_dat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mawd_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "#modify these according to output from above!!\n",
    "lim = [awd_dat['DateTime'][start],awd_dat['DateTime'][end]]\n",
    "clip_dat = act.clip_dat(lim,awd_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just run these cells in order to extract comments and write Mtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing/playing w code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = fn['cal']\n",
    "\n",
    "fn_pref,fn_ext = os.path.splitext(fn)\n",
    "if fn_ext == '.csv':\n",
    "    log_dat = pd.read_csv(fn, keep_default_na=False)\n",
    "elif fn_ext == '.xls':\n",
    "    log_dat = pd.read_excel(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'watch_on':['Start','start'],'watch_off':['End','end']}\n",
    "kw_dat = {}\n",
    "for ii in keywords.keys():\n",
    "    val = np.where(log_dat.Comment.isin(keywords[ii]))[0]\n",
    "       #print(ii,val)\n",
    "    if len(val) > 0:\n",
    "        kw_dat[ii] = (log_dat.iloc[val])\n",
    "        log_dat.drop(log_dat.index[val],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dat['On'] = pd.to_datetime(log_dat['OnDate'].astype(str) +\n",
    "                                   ' ' + log_dat['OnTime'].astype(str) )\n",
    "log_dat['Off'] = pd.to_datetime(log_dat['OffDate'].astype(str) + ' ' + log_dat['OffTime'].astype(str) )\n",
    "log_dat = log_dat.to_dict(orient='list')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fmt = '%d-%b-%y %I:%M %p'\n",
    "\n",
    "st_time = np.array([ datetime.strftime(ii,dt_fmt) for ii in log_dat['Off'] ])\n",
    "en_time = np.array([ datetime.strftime(ii,dt_fmt) for ii in log_dat['On'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07-Feb-16 01:00 PM', '07-Feb-16 02:30 PM'),\n",
       " ('08-Feb-16 01:00 PM', '08-Feb-16 02:30 PM'),\n",
       " ('08-Feb-16 09:30 PM', '09-Feb-16 07:00 AM'),\n",
       " ('09-Feb-16 02:00 PM', '09-Feb-16 04:00 PM'),\n",
       " ('10-Feb-16 10:00 AM', '10-Feb-16 12:00 PM'),\n",
       " ('10-Feb-16 09:30 PM', '11-Feb-16 07:00 AM'),\n",
       " ('11-Feb-16 09:00 AM', '11-Feb-16 09:40 AM'),\n",
       " ('11-Feb-16 03:00 PM', '11-Feb-16 05:00 PM')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_time = list(zip(st_time, en_time))\n",
    "mk_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_list = [[x,y,z] for x in st_time.tolist() for y in en_time.tolist() for z in log_dat['Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_list = []\n",
    "for i in range(0, len(st_time)):\n",
    "    tmp = [[st_time[i],en_time[i]],log_dat['Comment'][i]]\n",
    "    mk_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_list=[[[st_time[i],en_time[i]],log_dat['Comment'][i]] for i in range(0,len(st_time))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_tuple = list(zip(st_time,en_time,log_dat['Comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07-Feb-16 01:00 PM', '07-Feb-16 02:30 PM', 'Fake, for bug testing'),\n",
       " ('08-Feb-16 01:00 PM', '08-Feb-16 02:30 PM', '3T'),\n",
       " ('08-Feb-16 09:30 PM', '09-Feb-16 07:00 AM', 'Sleep study'),\n",
       " ('09-Feb-16 02:00 PM', '09-Feb-16 04:00 PM', '7T'),\n",
       " ('10-Feb-16 10:00 AM', '10-Feb-16 12:00 PM', 'MEG'),\n",
       " ('10-Feb-16 09:30 PM', '11-Feb-16 07:00 AM', 'Sleep study'),\n",
       " ('11-Feb-16 09:00 AM', '11-Feb-16 09:40 AM', 'Infusion'),\n",
       " ('11-Feb-16 03:00 PM', '11-Feb-16 05:00 PM', 'MEG')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_time = list(awd_dat['DateTime'])\n",
    "tmp_list = []\n",
    "exist_list = []\n",
    "for block in mk_tuple:\n",
    "    tmp = ()\n",
    "    exist = ()\n",
    "    for time in block[0:2]:\n",
    "        try:\n",
    "            tmp = tmp+(dat_time.index(time),)\n",
    "            exist=exist+(True,)\n",
    "        except:\n",
    "            if time<dat_time[0]:\n",
    "                tmp=tmp+(0,)\n",
    "            elif time>dat_time[-1]:\n",
    "                tmp=tmp+(len(dat_time)-1,)\n",
    "            exist=exist+(False,)\n",
    "    tmp = tmp+(block[2],)\n",
    "    exist_list.append(exist)\n",
    "    tmp_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,tup in enumerate(tmp_list):\n",
    "    if (exist_list[idx] == (False,False)):\n",
    "        tmp_list.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 74, '3T'),\n",
       " (494, 1064, 'Sleep study'),\n",
       " (1484, 1604, '7T'),\n",
       " (2684, 2804, 'MEG'),\n",
       " (3374, 3944, 'Sleep study'),\n",
       " (4064, 4104, 'Infusion'),\n",
       " (4424, 4544, 'MEG')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 74, 494, 1064, 1484, 1604, 2684, 2804, 3374, 3944, 4064, 4104, 4424, 4544]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y for z in [x[0:2] for x in tmp_list] for y in z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real notebook continues here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(act)\n",
    "#Make master mk_idx\n",
    "mk_idx,comments=act.get_markers(awd_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read logs\n",
    "mc_dict = {} #for Mtimes\n",
    "for name in fn.keys():\n",
    "    if os.path.isfile(fn[name]):\n",
    "        c_dict={}\n",
    "        log_dat,kw_dat,comments_tmp = act.read_log(fn[name],awd_dat)\n",
    "        mk_idx[name]=log_dat['idx']\n",
    "        \n",
    "        #process comments\n",
    "        zipped_pairs = zip(comments_tmp[0].tolist(),comments_tmp[1])\n",
    "        c_dict['comments'] = [x for _, x in sorted(zipped_pairs)]\n",
    "        c_dict['idxs'] = np.sort(comments_tmp[0]).tolist()\n",
    "        mc_dict[name]=c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(act)\n",
    "act.write_Mtimes_new(awd_dat,mk_idx,os.path.join(out_dir,sub_long),mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = {}\n",
    "del_com={}\n",
    "for name in fn.keys():\n",
    "    if name in mk_idx.keys():\n",
    "        plots[name]=mk_idx[name] - start\n",
    "        del_com[name]=((np.where(plots[name]<0)[0])//2).tolist()[::2]\n",
    "        plots[name]=plots[name][np.where(plots[name]>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms=[]\n",
    "idxs=[]\n",
    "for mm in mc_dict.keys():\n",
    "    print(mm)\n",
    "    idxs= idxs +(mc_dict[mm]['idxs'])\n",
    "    coms= coms + (mc_dict[mm]['comments'])\n",
    "    if mm in del_com.keys():\n",
    "        for i in range(0,len(del_com[mm])):\n",
    "            idxs.pop(0)\n",
    "            coms.pop(0)\n",
    "zipped_pairs = zip(idxs,coms)\n",
    "gc_coms = [x for _, x in sorted(zipped_pairs)]\n",
    "gc_idx = np.sort(idxs) - start\n",
    "\n",
    "gc=[np.asarray(gc_idx),gc_coms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots['cal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(act)\n",
    "\n",
    "act.plot_awd(clip_dat,plots,max_act=500,show=False,comments=gc,fn_pref=os.path.join(out_dir,sub_long+'_M+logs'),plot_type='single',debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(act)\n",
    "\n",
    "act.plot_awd(clip_dat,plots,max_act=250,show=False,comments=gc,fn_pref=os.path.join(out_dir,sub_long+'_M+logs_zoom'),plot_type='single',debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
